\documentclass[a4paper,english]{ifimaster}

\usepackage[utf8]{inputenc}
\usepackage{babel,duomasterforside}
\usepackage{hyperref}
\usepackage[backend=biber,style=authoryear,bibencoding=utf8]{biblatex}
\usepackage{minted}
\usepackage{graphicx}
\graphicspath{ {./images/} }
\usepackage{booktabs}

% Style Chapters
\usepackage[T1]{fontenc}
\usepackage{titlesec, color}
\definecolor{gray75}{gray}{0.75}
\newcommand{\hsp}{\hspace{20pt}}
\titleformat{\chapter}[hang]{\Huge\bfseries}{\thechapter\hsp\textcolor{gray75}{|}\hsp}{0pt}{\Huge\bfseries}

\nonstopmode{}
\addbibresource{citations.bib}

\title{Master Thesis}
\subtitle{Leveraging Language Tooling for Better Voice Coding}
\author{Gaute Berge}

\begin{document}

\duoforside[dept={Department of Informatics},
program={Informatics: Programming and System Architecture},
long]

\frontmatter{}
\chapter*{Abstract}
Software developers spend a lot of time working on a computer.
This makes them particular susceptible to Repetitive Strain Injuries (RSI), which can be detrimental to one's career.
Recently there have been great advancements in hands-free input systems that allow users to control a computer using their voice and/or an eye-tracker.
These systems can be customized using one or more scripting languages, which allows users to acquire much higher proficiency than what was previously thought possible for someone without full use of their hands.
There is however a steep learning curve, and a lot of work that goes into iteratively creating voice commands that allows for a fluent workflow.
The goal of this thesis is to uncover techniques to automate this process, and increase the productivity of programmers coding with their voice.

\tableofcontents{}
\listoffigures{}
\listoftables{}

% \chapter*{Preface}

\mainmatter{}

\chapter{Introduction}
Due to the prevalence of RSI in the tech industry, as well as the existence of other conditions that might limit a persons use of their arms/hands, the availability
of alternative input methods for programmers is extremely important.
Hands-free input technology enables people who would not otherwise be able to work on the computer to do so.
Enabling people to use standard applications such as web browsers, text editors, etc.\ is a complex problem in and of itself, and the domain of programming
introduces its own set of additional complexities.
Vocal programming, as coined by~\parencite{Arnold}, is the act of writing computer programs by dictating into the microphone as the primary input method as opposed to using a keyboard and mouse.
Programming differs from normal prose dictation in many subtitle ways such as higher frequency of special characters, and higher emphasis on editing text (and less emphasis on writing text).
Software developers also use a wider variety of applications and tools in their day-to-day work which all needs to be made accessible for vocal programmers.
Many of the solutions proposed by researchers involve a specialized environment for programming, such as a structure oriented editor.
As will be discussed in~\ref{scgp}, this approach comes with some trade-offs.
Recent advancements in programming language tooling, such as Microsoft's ``Language Server Protocol'', and GitHub's ``TreeSitter'' is bringing the power of IDEs to standard text editors.
In this paper I will use \textbf{Talon}, a general purpose system for hands-free input, to show how modern programming language
   tools can be leveraged to improve the workflow of vocal programmers in the programming environments they are already used to.

\section{Motivation}
\paragraph{Injuries}
Here I will cover research related to injuries such as RSI in the tech industry.
\paragraph{Learning Curve}
Here I explain breifly some of the difficulties people have when starting out with voice coding.
Learning curve is the biggers, and is extasterbated by the fact that you need
to be able to code in order to use the system profeciently, which leads to a 
chicken-egg situation.
\paragraph{Special Case vs. General Purpose}\label{scgp}

\section{Research Questions}
\paragraph{Question 1:}
Can the benefits of structural editors be achieved in text oriented environments for vocal programmers?
\paragraph{Question 2:}
Can modern language tooling be leveraged to make vocal programming more efficient?

\section{Approach}

\section{Chapter Overview}
\paragraph{Chapter 1:} \nameref{background} 


\chapter{Background}\label{background}
In this section I will cover the history of voice coding (Dragon, NatLink, Dragonfly, Caster etc\ldots)
as well as the state of the art language tooling. (LSP and TreeSitter).
I will also cover something about the Elm programming language, as I will be using that in my analysis.

\section{Accessibility}%
\label{sec:accessibility}

\section{History of Voice Coding}

\paragraph{Dragon NaturallySpeaking}
The worlds first large-vocabulary general purpose dictation system.
Dragon is in many ways the foundation for many of tools like Talon.
Some voice systems use it as just a speach engine, but it also provides other functionality like mouse control.
Available for mac and windows, but discontinued for mac.% when??
The mac version is still available on eBay, and still works. % maybe something here about the download stuff.

\paragraph{NatLink}
While dragon alone is a very powerful dictation system, it's customization ability is limited.
Dragon does provide a simple scripting language in the pro edition, but it has very limited capabilities compared to
moden general purpose scripting languages.
In 1999, NatLink was developed to solve this problem. It is a macro system for dragon which lets the user write macros that can be triggered by voice commands
in python.~\parencite{gould2001implementation}
Later on, more high level APIs were built on top on natlink such as dragonfly and caster. % Not really precise. Need to look into history here.

\paragraph{Dragonfly}
Higher-level scripting api on top of natlink.

\paragraph{Caster}
Another layer on top of dragonfly. Not totally sure if worth discussing.

\paragraph{VoiceCode}
Seems like this was a popular dictation system at some point. There are papers on it, so might be worth discussing.

\section{Dictation}
Dictation, in this context, is the act of speaking phrases into a microphone and have those phrases translated into text.
This is made possible by a technique called \textit{Speech Recognition} which combines techniques from natural language processing
and signal processing. The soundwaves from the user is captured by the microphone, processed, and sent off to a machine learning algorithm
that will try to fit the input into a sequence of words, or a sentence, in the target language (i.e English). Speech recognition
has been around for a while, but has just in the past decade seeing huge boosts in accuracy, partly due to the Discovery of deep learning.
Voice controlled applications are built on top of programs implementing the speech recognition, often referred to as ``Speech Recognition Engines''.

Beyond the technical aspect, efficient dictation also requires a great deal of attention from the user.
To achieve high accuracy while dictating, it is not sufficient, or at least not optimal, to simply speak as one normally would.
New users will have to practice things like speaking at a consistent pace and volume, and being aware of their distance to the microphone (to try not to vary too much).
Some users will also need to enunciate their words much more than they are used to, especially if they are not native speakers of the language in which they are dictating.
Different users can experience very different results with the same engine simply due to a high degree of variation between peoples voices.
Users also need to configure and personalize the system by adding words to the vocabulary of the engine, and training the engine on words that they are
having a hard time getting recognized. This process is often very incremental, and optimal results might not be achieved until the user has
use the system for a while.

People not used to dictating will also experience a high degree of cognitive load in the beginning, which will slow down their work.
Dictation works better when the user speaks in full sentences, as opposed to single words, or even short phrases.
Users will therefore have to learn to plan out their sentences before starting to speak.
This can feel very different from the experience of typing on a keyboard, but it is a challenge that is surmountable by practice.

\paragraph{Command First vs Data First}
Two different dication strategies.
Command first = Output only triggered when a command is triggered by speaking a particular phrase.
Data first = The user can speak without keywords. The system should infer capitalization and punctuation.
Here i will describe the tradeoff between these two.

\paragraph{Homophones}
A homophone is a word that sound the same as another word, but have different meaning.
These groups of words may be spelled the same or differently.
For example, ``rose'' may refer to the past tense of rise, or the flower.
The word ``pair'' is \textit{homophonic} to ``pear'', and ``pare''.
Homophones that are also spelled the same are also known as homographs, whereas the ones spelled differently are called heterographs.
In the context of vocal programming, and speech recognition in general, we are only interested in heterographs as we do not consider
the underlying meaning of a phrase beyond whether or not it was what the user intended to input.
Although we are only considering this subset, I will be using the more general term homophone as this is more widely used in the documentation
of the system I will be discussing.

Homophones are a very big challenge for vocal programming.
Speech recognition engines are not able to reliably distinguish between homophones.
Often they can still infer the correct word based on the context in which it was used.
For example, Dragon can reliably recognize the phrase ``I saw that with my eye'' correctly despite the fact that ``I'' and ``eye'' are homophones.
However, if they are not spoken within a sentence, they cannot be distinguished on the user will likely see only one of the options every time.
This problem is a bigger challenge for vocal programing than prose dictation because program text is not formed by English sentences, and more words needs to be
spoken one at a time.

There are however techniques for alleviating this problem, which will be discussed in the section on~\nameref{dealing_with_homophones}



\section{PL Theory}
As much of the work is related to analysing programs, I should cover some general stuff abuut languages.
Not sure how much detail is appropriate here, but could be a source for a lot of content.
Possible subjects: Parsing, type checking/inference, scopes, etc.

\section{Language Server Protocol}
Client-server based approach to reuable language IDE features.
I'll compare this to the traditional IDE approach (Eclipse / Intellij)
and discuss how this can be used by other tools than editors.

\section{TreeSitter}
TreeSitter is a system for incremental parsing developed by GitHub.
It was conceived as a solution to the problem of instant semantic syntax highlighting,
but is also used in the implementation of some language servers.

\section{Elm}
In this thisis I will be using Elm as the subject of the alysis.
Elm is a feature rich, but relatively simple language.
Some knowledge of Elm is useful for the reader, no experience is required.
Primarily I will cover the features of Elm that introduces new identifiers into the scope,
as these will be relevant when generating voice commands later.

\chapter{Talon}\label{talon}
Talon is a system that enables people to use a computer with hands-free input methods.
It supports controls using voice commands, noise input, and eye tracking.
The features of Talon are customizable and extendable through a scripting api which uses Python in conjunction with
a simpler, domain specific scripting language called ``TalonScript''.
Through this api users can define custom actions that responds to certain noises, voice commands, or where the user is looking.
These actions can be very simple, such as emulating a sequence of keystrokes, but can also be arbitrary python functions
that can send commands to the operating system, or make network requests.
This section will serve as an overview of Talon and how it is used to make different features of a computer accessible to people with disabilities.

\begin{figure}[htpb]
    \centering
    \includegraphics[width=0.3\linewidth]{talon_logo.png}
    \caption{Talon Logo}%
    \label{fig:talon_logo}
\end{figure}

\section{Current state of the project}
The project is currently in version 0.1.4 and is available through public release or a private beta.
Talon was previously only available on macOS with the Dragon engine, but it was recently made available for Windows 10 and Linux.
It is now also possible to use talon with different speech engines such as ``wav2letter''.
The project is undergoing very rapid development, and beta users are seeing multiple minor releases each week.

\section{Distribution and Monetization}
Talon is freely distributed, but closed source.
Its creator, Ryan Hileman, works full-time on the project and is solely funded through Patreon which is a site that allows people to make monthly donations.
There are currently 225 users donating on Patreon, pledging a combined \$3,526 per month[24.04.20].

\section{Community}
The community is organized through a Slack channel where users can discuss topics related to using Talon such as equipment, health, etc.
This is also where users go to seek help and discuss issues with the project.
Hileman is usually available to answer question and help users, and is very quick to respond.
Although the project is closed source, people can still contribute two user-level code and documentation.

\section{Learning Resources and Documentation}
New users will face a quite steep learning curve.
The official documentation is largely incomplete, so users are encouraged to learn the api primarily through looking at examples.
Most new users we learn the basics off using Talon by reading Emily Shea's guide ``Getting Started with Voice Driven Development''.
This guide covers the most essential concepts you need to learn to use Talon such as inputting basic keyboard combinations, dictating with formatters, bringing up the command reference, as well as some general tips for becoming proficient with Talon.
The official documentation also refers to the official examples repository which provides a handful of examples that users can download directly, or use as reference for writing their own scripts.
A common way to get started to download a larger command set such as knausj\_talon which comes with a lot of functionality out-of-the-box.
There is also an unofficial documentation repository.
While this covers more than the official documentation, and is very useful, it is also incomplete, and is not guaranteed to be immediately updated if the api is changed.

\section{Using Talon}
In this section I will explain Talon is used to enable full control of the desktop environment.
This is relevant because the reader needs to see the advantages and disadvantages of using talon compared to using a keboard.
Talon does not come with any voice commands built-in.
In the directory where Talon is installed, there is a folder called \textbf{user}.
When scripts are added to this folder, they are immediately loaded, and the system will listen for any voice commands defined in the scripts.
Voice commands are implemented by using TalonScript, in conjunction with Python.
How this works will be explained in more detail in the section~\nameref{wvc}, but I will also be providing
a few simple examples in this section to give the reader a better understanding of what is going on.

\paragraph{Example Talon Script:}
\begin{verbatim}
# hello world command
hello world: "Hello World"
\end{verbatim}

The above example shows a talon script that defines voice command such that uttering the phrase ``hello world''
results in the text ``Hello World'' being outputted.
Text being outputted correspondence to
a sequence of emulated keyboard presses.
Lines starting with a \textbf{\#} are comments.
Saving this file in the talon user directory with the file extension \textbf{.talon} will make this command available globally.
In the rest of this section I will explain how people are able to control their computer and some common applications with Talon.
% should explain some general concepts such as command mode versus dictation mode

\subsection{The Basics}
The first step towards being able to use the computer is access basic functionality like switching applications, and pressing keys.
\textbf{knausj\_talon} provides many such features, and I will be using examples from that command set.

\paragraph{The Alphabet:}
One of the most basic actions you can perform is to utter a phrase that will emulate a single keystroke.
The most convenient solution would be to map the spoken form of each letter to the action that input that key.
So the phrase ``A'' would would press the \textbf{a} key, and so on.
This is however not practical because many of the English letters are in homophone groups.
For example, the letter ``I'' is homophonic to the word ``eye'', the letter ``B'' is homophonic to ``be'' and ``bee''.
Therefore it is necessary to define a separate alphabet for keystrokes.
One solution is to use a standardized phonetic alphabet, such as \textbf{The International Radiotelephony Spelling Alphabet}
(also known as \textbf{The NATO Phonetic Alphabet}) which maps easily distinguishable words to the letter the word begins with.
In this alphabet ``Alpha'' map to ``a'', ``Golf'' map to ``g'', etc.
As this alphabet was designed for unambiguously spelling words even with poor connections it has very high accuracy.
This is however not practical solution due to some words being very long. ``November'' is three syllables long, which
is not ideal for such a basic command that will be used often.
Therefore the alphabets being used are designed to be as quick and easy to say as possible, sometimes at the cost of
being less mnemonic. An example can be seen in Table~\ref{alphabet}, but users will often make their own
modifications. With this alphabet, to press the ``n'' key the user would say ``near''.

\begin{table}[htpb]
    \centering
    \label{alphabet}
    \caption{Alphabet used in knausj\_talon}
    \begin{tabular}{ c c | c c }
        air & a & bat & b \\
        cap & c & drum & d \\
        each & e & fin & f \\
        gust & g & harp & h \\
        sit & s & jail & j \\
        crunch & c & look & l \\
        made & m & near & n \\
        odd & o & peck & p \\
        quench & q & red & r \\
        sun & s & trap & t \\
        urge & u & vest & v \\
        whale & w & plex & x \\
        yell & y & zip & z
    \end{tabular}
\end{table}

\paragraph{Basic Keys:}
Special symbols and action keys can be triggered in the expected way.
To press the space-key, the user would say ``space''.
To input the symbol \textbf{+}, the user would say ``plus''.
Some symbols have abbreviated forms, and some have simplified aliases.
The symbol \textbf{?} can be entered by saying either ``question mark'', or simply ``question'',
while the asterisk symbol \textbf{*} can be entered using either ``asterix'' or ``star''.
Numbers can also be entered directly in command mode.
Since the directions (left, right, down, up) can be hard to recognize, the commands for
pressing the corresponding arrow key is prefixed by ``go'', e.i ``go left'' will press the left arrow key.
All of this is fully customizable, but requires basic knowledge of Python.
Some basic keys are entered very often, so it might be beneficial to
choose a different word to trigger case with names longer then one syllable.
Travis Rudd % make sure is a reference before
uses the phrase ``slap'' to press \textbf{enter}, which is an example of
choosing non-mnemonic command to achieve higher efficiency.
% refer to full symbol table/grammar?

\paragraph{Complex Keys:}
A modifier key, or simply a modifier is a key that when pressed in conjunction with another
modifies the behavior of the other key. This includes keys like \textbf{control}, \textbf{shift}, \textbf{alt/option}
, \textbf{super}, and combinations of these. \textbf{super} as a general term to refer to the \textbf{windows-key} (Windows), or \textbf{command} (Mac). Some of these combinations of names, such as (\textbf{shift+control+alt})
is called \textbf{meh}, and (\textbf{med}+\textbf{super}) is called \textbf{hyper}.
Complex keys are those that require the use of one or more modifier.
To enter an uppercase ``A'', one would type ``a'' while holding \textbf{shift}, which we denote \textbf{shift-a}.
To trigger a complex key with talon the user would utter one or more modifier followed by the basic key.
An uppercase ``A'' can then be entered using the phrase ``shift air''.

\subsection{Dictation}
% Should probably explain dictation mode, and Dragon mode at some point
As previously mentioned, Talon is usually operated in command mode
which means that if the user starts dictating, nothing will happen
unless that spoken phrase is recognized as a command by the grammar.
To circumvent the user having to switch frequently between dictation mode and command mode,
knausj\_talon comes with commands for entering text with different formatting, as well as
different properties and how the commands are recognized.
Table~\ref{tab:formatters} shows how the phrase ``one two three'' will be formatted using a given formatter.
For example, saying ``speak one two three'' will output ``one two three'', while saying ``snake one two three''
will output ``one\_two\_three''. The name ``snake'' comes from ``snake case'' which is the name of the formatting
used for Python variables where words are separated by underscores.
This is essential for programming because of the frequency of text with different formatting compared to
normal English.

\begin{table}[htpb]
   \centering
   \caption{Formatters in knausj (excerpt)}
   \label{tab:formatters}
   \begin{tabular}{|c|c|}
      \toprule
      Formatter Name & Example Output \\
      \midrule
      camel & oneTwoThree  \\
      dotted & one.two.three  \\
      dunder & \_\_one\_\_twothree  \\
      folder & one/two/three/  \\
      hammer & OneTwoThree  \\
      kebab & one-two-three  \\
      long arg & --one-two-three  \\
      packed & one::two::three  \\
      smash & onetwothree  \\
      snake & one\_two\_three  \\
      speak & one two three  \\
      string & "one two three"  \\
      ticks & 'one two three'  \\
      title & One Two Three  \\
      upper & ONE TWO THREE  \\
      \bottomrule
   \end{tabular}
\end{table}

\subsection{Text Editing}
Here i will cover navigating a text editor with voice commands and eye-tracker.

\subsection{Web Browsing}
Vimium and Surfingkeys. How are these plugins used.

\subsection{Using The Terminal}
An essential part of the programming workflow. The terminal is accessible by default due to its text oriented interface.

\section{Dealing With Homophones}\label{dealing_with_homophones}
Here I will discuss how talon deals with homophones.

\section{Writing Voice Commands with Talon}\label{wvc}
\subsection{Rules}
\subsection{Actions}
\subsection{Contexts}
\subsection{Dynamic Lists}


\section{Editor Integration}
Here I will cover how Talon can be integrated with Vim and IntelliJ, and also cover how to edit text without editor integration.
\subsection{Shortcut Mappings}
The simplest integration. 
\subsection{Server Client}
Send commands from talon over http (IntelliJ)
\subsection{Vim}
Cover how vim is integrated in the community package.

\chapter{Methodology And Evaluation}\label{methodology_and_evaluation}
I might use a mix of quantitative and qualitative methods. (multi- strategy) % read creswell,2018
I could hold interviews with users of Talon to gather both types of data.

\paragraph{Speed Testing}
I can test the users programming speed with and without my system.
Here I must consider factors such as performance anxiety.
The programs they would be asked to dictate would have to be carefully crafted in order to have a consistent difficulty level
across the test. 
Should they dictate the same program twice, or two different? How can I be sure they are similarly difficult?
Should I change the order of the two tests?
This might well be a good measurement. I'll discuss why this paragraph.


\section{Qualitative}
I can gather qualitative data by having the user program using my system and ask them whether or not they find using it to be an improvement.
The disadvantage to this approach is that the system might have a learning curve which makes the initial impression
worse than it would have been over time.

\section{Quantitative}
One quantitative measure I could use is to analyse larger codebases to see how the predicted time to speak common identifiers change.
If I can count the number of syllables in a word I can compare the length of normal phrases need to produce a given function in a code base and compare
it to that of my system. This analysis can be weighted by the frequency of said identifiers.
The advantage of this approach is simplicity in that I don't depend on external users.
One interesting point here is to see how the result of this analysis relate to the results gathered from interviews.
\subsection{Data Collection}
Analyze the Elm implementation of real world app (https://github.com/rtfeldman/elm-spa-example)

\chapter{The Project}\label{the_project}
The goal of this project is to create a prototype of a system that can generate voice commands
for talon from a source file in a given program language to the increase accuracy and efficiency of programming.
The result should take the form of a server that can be easily integrated into any editor as a plug-in
which handles day generational voice commands and the communication with talon.
While the final version of the system should be general enough to handle any language, and be integratable with any the editor,
the prototype only aims to handle the \textit{Elm} programming language in the \textit{Neo-vim} editor.
This chapter will describe the design and architecture of the system.

\paragraph{Problem Description:}% concise description of the problem. maybe this should, earlier?
todo



\section{Voice Command Generation}%
\label{sec:voice_command_generation}
How to generate voice commands?
Cover how the spoken form of different identifiers will be.
Overview of different classes of identifiers (imports, aliases, functions, variables, types etc).
\subsection{Abbreviations}
peekCString->``P C S''. How does this relate to normal auto complete?


\section{Design Goals}%
\label{sec:design_goals}
configurable, accuracy, intuitive/consistent (user should not have to look up the generated commands), 
shortest commands possible

\section{Architecture}%
\label{sec:architecture}
editor<->my system<->talon

\section{Implementation}%
\label{sec:implementation}
implementation details such as programming language etc




\chapter{Results}\label{results}
\section{Interviews}
\section{Analysis}
\section{Comparing Results From Different Methods}


% Donald Knuth often says smart stuff ~\parencite{Knuth:2007:CPA:1283920.1283929}.
\backmatter{}
\printbibliography{}

\end{document}
